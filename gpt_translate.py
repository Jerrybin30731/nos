# -*- coding: utf-8 -*-
"""GPT-translate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z_Q_eIDylN1fORBsa9vfL90fLm5WLrse
"""

User_API = ' User API keys of openai'

import nltk
nltk.download('punkt')
! pip install openai
! pip install pypdf
! pip install requests
! pip install pytxt

from nltk.tokenize import sent_tokenize #Read and print the doc

with open('txt name', 'r') as file:
    text = file.read()

sentences = sent_tokenize(text)  # 使用標點符號來分割文本

for sentence in sentences:
    print(sentence)

import openai

openai.api_key = (API)

with open('txt name', 'r') as file:
    text = file.readlines()

completion = openai.ChatCompletion.create(
  model="gpt-3.5-turbo", #Import the gpt engine
  messages=[
        {"role": "system", "content": "請你成為文件翻譯的小幫手，請協助翻譯以下技術文件，以繁體中文輸出"},
        {"role": "user", "content": text[8]}, #Translate for specific line
    ]
)
print(completion.choices[0].message['content'])

import openai
import nltk
import time
from nltk.tokenize import sent_tokenize


openai.api_key = (gg)

with open('txt name', 'r') as file:
    text = file.read()

sentences = sent_tokenize(text)

for sentence in sentences:
    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "你是一個文件翻譯的助手，請將以下的英文技術文件翻譯成繁體中文。"},  #Translate English into mandarin
            {"role": "user", "content": sentence},
        ]
    )
    time.sleep(20) #Set it to every 20 seconds because of the gpt limit
    print(completion.choices[0].message['content'])